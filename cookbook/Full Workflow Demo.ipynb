{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "from flytekit.common import utils as _utils\n",
    "from flytekit.sdk import test_utils as _test_utils\n",
    "from flytekit.configuration import set_flyte_config_file\n",
    "from flytekit.common.tasks.presto_task import SdkPrestoTask\n",
    "from flytekit.sdk.tasks import inputs\n",
    "from flytekit.sdk.types import Types\n",
    "from flytekit.configuration import platform\n",
    "from os import environ\n",
    "\n",
    "environ[\"version\"] = \"25\"\n",
    "environ[\"spec_version\"] = \"25-1\"\n",
    "environ[\"FLYTE_INTERNAL_IMAGE\"] = \"docker.io/lyft/flytesnacks:datacouncil-{}\".format(environ[\"version\"])\n",
    "set_flyte_config_file(\"staging.config\")\n",
    "environ[\"FLYTE_INTERNAL_CONFIGURATION_PATH\"] = \"/root/staging.config\"\n",
    "\n",
    "def print_console_url(exc):\n",
    "    print(\"http://{}/console/projects/{}/domains/{}/executions/{}\".format(platform.URL.get(), exc.id.project, exc.id.domain, exc.id.name)) \n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                    endpoint_url='http://localhost:30084',\n",
    "                    aws_access_key_id='minio',\n",
    "                    aws_secret_access_key='miniostorage',\n",
    "                    config=Config(signature_version='s3v4'),\n",
    "                    region_name='us-east-1')\n",
    "\n",
    "def upload_file(f, ref):\n",
    "    mod = ref.lstrip(\"s3://\")\n",
    "    bucket, path = mod.split(\"/\", 1)\n",
    "    s3.Bucket(bucket).upload_file('image.py',path)\n",
    "    \n",
    "from IPython.display import Image, display\n",
    "def display_images(paths):\n",
    "    for p in paths:\n",
    "        display(Image(p))\n",
    "\n",
    "def print_schema(schema):\n",
    "    with _test_utils.LocalTestFileSystem() as sandbox:\n",
    "        # load schema data\n",
    "        schema.download()\n",
    "        df = pd.read_parquet(schema.local_path)\n",
    "    print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample ML Model Pipeline\n",
    "\n",
    "Let's start developing a more serious model. This involves pulling data using presto, transforming parquet to CSV and finally training an XGBoost Model on SageMaker.\n",
    "\n",
    "### 1) Query the data\n",
    "#### a. Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [13/Jul/2020 10:58:55] \"GET /callback?code=gE0h7dQVrtW8ACEiQHW4&state=05PoGI4gZ51L9shCDflg75hG_iVtRjxABaH0n82-O8qOAMVtg-OD8g HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created execution.\n",
      "http://flyte-staging.lyft.net/console/projects/flytekit/domains/development/executions/mggnq77a7x\n",
      "Waiting for execution to complete...\n",
      "Done!\n",
      "    col0 col1 col2 col3 col4  col5   col6 col7 col8\n",
      "0      1   85   66   29    0  26.6  0.351   31    0\n",
      "1      8  183   64    0    0  23.3  0.672   32    1\n",
      "2      1   89   66   23   94  28.1  0.167   21    0\n",
      "3      0  137   40   35  168  43.1  2.288   33    1\n",
      "4      5  116   74    0    0  25.6  0.201   30    0\n",
      "..   ...  ...  ...  ...  ...   ...    ...  ...  ...\n",
      "762   10  101   76   48  180  32.9  0.171   63    0\n",
      "763    2  122   70   27    0  36.8  0.340   27    0\n",
      "764    5  121   72   23  112  26.2  0.245   30    0\n",
      "765    1  126   60    0    0  30.1  0.349   47    1\n",
      "766    1   93   70   31    0  30.4  0.315   23    0\n",
      "\n",
      "[767 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "get_train_data2 = SdkPrestoTask(\n",
    "    task_inputs=inputs(),\n",
    "    statement=\"\"\"\n",
    "    SELECT * \n",
    "    FROM hive.flyte.datacouncildemo_train\n",
    "    \"\"\",\n",
    "    output_schema=Types.Schema(),\n",
    "    discoverable=True,\n",
    "    discovery_version=\"3\",\n",
    ")\n",
    "\n",
    "\n",
    "get_train_data2.register(project=\"flytesnacks\", domain=\"development\", name=\"get_train_data\", version=environ[\"version\"])\n",
    "\n",
    "task_exec = get_train_data2.register_and_launch(project=\"flytekit\", domain=\"development\", inputs={\"ds\": '2020-07-05'})\n",
    "print(\"Created execution.\")\n",
    "print_console_url(task_exec)\n",
    "print(\"Waiting for execution to complete...\")\n",
    "task_exec.wait_for_completion()\n",
    "print(\"Done!\")\n",
    "\n",
    "print_schema(task_exec.outputs['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Get Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tsk:flytesnacks:development:get_validation_data:24'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_validation_data = SdkPrestoTask(\n",
    "    task_inputs=inputs(),\n",
    "    statement=\"\"\"\n",
    "    SELECT * \n",
    "    FROM hive.flyte.datacouncildemo_validation\n",
    "    \"\"\",\n",
    "    output_schema=Types.Schema(),\n",
    "    discoverable=True,\n",
    "    discovery_version=\"2\",\n",
    ")\n",
    "\n",
    "# No need to run this. it's just a copy of the training data task.\n",
    "# In a real scenario, we will probably query a huge data set then apply some common algorithm to split the datasets \n",
    "#  (e.g. 20-80)\n",
    "get_validation_data.register(project=\"flytesnacks\", domain=\"development\", name=\"get_validation_data\", version=environ[\"version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Transform Parquet to CSV (SageMaker requires that)\n",
    "Somebody has already writen a common python task that transforms parquet to csv. Let's just import that task and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flytekit.common.tasks.task import SdkTask\n",
    "transform_parquet_to_csv = SdkTask.fetch(project=\"flytesnacks\", domain=\"development\", name=\"transform_parquet_to_csv\", version=\"24\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Let's write the Training Step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tsk:flytesnacks:development:xgboost_hpo_task2:24'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flytekit.sdk.tasks import inputs\n",
    "from flytekit.sdk.types import Types\n",
    "from flytekit.sdk.workflow import workflow_class, Input, Output\n",
    "from flytekit.common.tasks.sagemaker import training_job_task, hpo_job_task\n",
    "from flytekit.models.sagemaker import training_job as training_job_models, hpo_job as hpo_job_models\n",
    "from flytekit.sdk.sagemaker import types as _sdk_sagemaker_types\n",
    "xgboost_hyperparameters = {\n",
    "    \"base_score\": \"0.5\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"csv_weights\": \"0\",\n",
    "    \"dsplit\": \"row\",\n",
    "    \"grow_policy\": \"depthwise\",\n",
    "    \"lambda_bias\": \"0.0\",\n",
    "    \"max_bin\": \"256\",\n",
    "    \"max_leaves\": \"0\",\n",
    "    \"normalize_type\": \"tree\",\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"one_drop\": \"0\",\n",
    "    \"prob_buffer_row\": \"1.0\",\n",
    "    \"process_type\": \"default\",\n",
    "    \"rate_drop\": \"0.0\",\n",
    "    \"refresh_leaf\": \"1\",\n",
    "    \"sample_type\": \"uniform\",\n",
    "    \"scale_pos_weight\": \"1.0\",\n",
    "    \"silent\": \"0\",\n",
    "    \"skip_drop\": \"0.0\",\n",
    "    \"tree_method\": \"auto\",\n",
    "    \"tweedie_variance_power\": \"1.5\",\n",
    "    \"updater\": \"grow_colmaker,prune\",\n",
    "}\n",
    "\n",
    "alg_spec = training_job_models.AlgorithmSpecification(\n",
    "    input_mode=_sdk_sagemaker_types.InputMode.FILE,\n",
    "    algorithm_name=_sdk_sagemaker_types.AlgorithmName.XGBOOST,\n",
    "    algorithm_version=\"0.72\",\n",
    "    metric_definitions=[training_job_models.MetricDefinition(name=\"Minimize\", regex=\"validation:error\")]\n",
    ")\n",
    "\n",
    "xgboost_train_task2 = training_job_task.SdkSimpleTrainingJobTask(\n",
    "    training_job_config=training_job_models.TrainingJobConfig(\n",
    "        instance_type=\"ml.m4.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=25,\n",
    "    ),\n",
    "    algorithm_specification=alg_spec,\n",
    "    cache_version='2',\n",
    "    cacheable=True,\n",
    ")\n",
    "\n",
    "xgboost_hpo_task2 = hpo_job_task.SdkSimpleHPOJobTask(\n",
    "    training_job=xgboost_train_task2,\n",
    "    max_number_of_training_jobs=10,\n",
    "    max_parallel_training_jobs=5,\n",
    "    cache_version='2',\n",
    "    retries=2,\n",
    "    cacheable=True,\n",
    ")\n",
    "\n",
    "xgboost_hpo_task2.register(project=\"flytesnacks\", domain=\"development\", name=\"xgboost_hpo_task2\", version=environ[\"version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lp:flytesnacks:development:TrainingWorkflow:24-1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flytekit.sdk.workflow import workflow_class, Input, Output\n",
    "from flytekit.models.sagemaker.training_job import StoppingCondition\n",
    "from flytekit.models.sagemaker.hpo_job import HPOJobConfig, HyperparameterTuningObjective\n",
    "from flytekit.models.sagemaker.parameter_ranges import ParameterRanges, CategoricalParameterRange, ContinuousParameterRange, IntegerParameterRange\n",
    "\n",
    "@workflow_class()\n",
    "class TrainingWorkflow(object):    \n",
    "    # retrieve data\n",
    "    train_data = get_train_data2()\n",
    "    validation_data = get_validation_data()\n",
    "    \n",
    "    # transform data\n",
    "    train_csv = transform_parquet_to_csv(input_parquet=train_data.outputs.results)\n",
    "    validation_csv = transform_parquet_to_csv(input_parquet=validation_data.outputs.results)\n",
    "    \n",
    "    # train with HPO\n",
    "    train = xgboost_hpo_task2(train=train_csv.outputs.output_csv,\n",
    "                             validation=validation_csv.outputs.output_csv,\n",
    "                             static_hyperparameters=xgboost_hyperparameters,\n",
    "                             stopping_condition=StoppingCondition(\n",
    "                                max_runtime_in_seconds=43200,\n",
    "                             ).to_flyte_idl(),\n",
    "                             hpo_job_config=HPOJobConfig(\n",
    "                                hyperparameter_ranges=ParameterRanges(\n",
    "                                    parameter_range_map={\n",
    "                                        \"num_round\": IntegerParameterRange(min_value=1, max_value=100, scaling_type=_sdk_sagemaker_types.HyperparameterScalingType.LOGARITHMIC),\n",
    "                                    }\n",
    "                                ),\n",
    "                                tuning_strategy=_sdk_sagemaker_types.HyperparameterTuningStrategy.BAYESIAN,\n",
    "                                tuning_objective=HyperparameterTuningObjective(\n",
    "                                    objective_type=_sdk_sagemaker_types.HyperparameterTuningObjectiveType.MINIMIZE,\n",
    "                                    metric_name=\"validation:error\",\n",
    "                                ),\n",
    "                                training_job_early_stopping_type=_sdk_sagemaker_types.TrainingJobEarlyStoppingType.AUTO\n",
    "                            ).to_flyte_idl())\n",
    "    \n",
    "    model = Output(train.outputs.model, sdk_type=Types.Blob)\n",
    "    \n",
    "TrainingWorkflow.register(project=\"flytesnacks\", domain=\"development\", name=\"TrainingWorkflow\", version=environ[\"spec_version\"])\n",
    "TrainingWorkflow_lp = TrainingWorkflow.create_launch_plan()\n",
    "TrainingWorkflow_lp.register(project=\"flytesnacks\", domain=\"development\", name=\"TrainingWorkflow\", version=environ[\"spec_version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://flyte-staging.lyft.net/console/projects/flytesnacks/domains/development/executions/f7807b50d9ced48a9a15\n"
     ]
    }
   ],
   "source": [
    "exec = TrainingWorkflow_lp.launch(project=\"flytesnacks\", domain=\"development\", inputs={})\n",
    "print_console_url(exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for execution to complete...\n",
      "Done!\n",
      "\n",
      "Generated Model: s3://lyft-modelbuilder/metadata/propeller/staging/flytesnacks-development-f593fba5e141d4fea829/train/data/0/hpo_outputs/f593fba5e141d4fea829-008-f2657b81/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Waiting for execution to complete...\")\n",
    "exec.wait_for_completion()\n",
    "print(\"Done!\")\n",
    "print()\n",
    "print(\"Generated Model: {}\".format(exec.outputs[\"model\"].uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
