{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# How to write/use your custom types in a task?\n\nFlyte is a strongly typed framework for authoring tasks and workflows. But, there are situations when the existing set\nof types do not directly work. This is true with any programming language. This is when the languages support higher\nlevel concepts to describe User specific objects - like classes in python/java/c++, struct in C/golang, etc\n\nFlytekit allows modeling user classes similarly. The idea is to make an interface that is more productive for the\nusecase, but write a transformer that transforms the user defined type to one of the generic constructs in Flyte's\nType system.\n\nIn this example, we will try to model an example user defined set and show how it can be integrated seamlessly with\nFlytekit's typing engine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport shutil\nimport tempfile\nimport typing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FlyteContext is used only to access a random local directory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import Type\n\nfrom flytekit import FlyteContext, task, workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defined type here represents a list of Files on the disk. We will refer to it as ``MyDataset``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from flytekit.annotated.type_engine import TypeTransformer, TypeEngine\nfrom flytekit.models.core.types import BlobType\nfrom flytekit.models.literals import Literal, Scalar, Blob, BlobMetadata\nfrom flytekit.models.types import LiteralType\n\n\nclass MyDataset(object):\n    \"\"\"\n    Dataset here is a set of files that exist together. In Flyte this maps to a Multi-part blob or a directory\n    \"\"\"\n\n    def __init__(self, base_dir: str = None):\n        if base_dir is None:\n            self._tmp_dir = tempfile.TemporaryDirectory()\n            self._base_dir = self._tmp_dir.name\n            self._files = []\n        else:\n            self._base_dir = base_dir\n            files = os.listdir(base_dir)\n            self._files = [os.path.join(base_dir, f) for f in files]\n\n    @property\n    def base_dir(self) -> str:\n        return self._base_dir\n\n    @property\n    def files(self) -> typing.List[str]:\n        return self._files\n\n    def new_file(self, name: str) -> str:\n        new_file = os.path.join(self._base_dir, name)\n        self._files.append(new_file)\n        return new_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``MyDataset`` represents a set of files locally, but, when a workflow consists of multiple steps, we want the data to\nflow between the different steps. To achieve this, it is necessary to explain how the data will be transformed to\nFlyte's remote references. To do this, we create a new instance of\n:py:class:`flytekit.annotated.type_engine.TypeTransformer`, for the type ``MyDataset`` as follows\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The TypeTransformer is a Generic abstract base class. The Generic type argument here refers to the actual object\n  that we want to work with. In this case, it is the ``MyDataset`` object</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MyDatasetTransformer(TypeTransformer[MyDataset]):\n    _TYPE_INFO = BlobType(\n        format=\"binary\", dimensionality=BlobType.BlobDimensionality.MULTIPART\n    )\n\n    def __init__(self):\n        super(MyDatasetTransformer, self).__init__(\n            name=\"mydataset-transform\", t=MyDataset\n        )\n\n    def get_literal_type(self, t: Type[MyDataset]) -> LiteralType:\n        \"\"\"\n        This is useful to tell the Flytekit type system that ``MyDataset`` actually refers to what corresponding type\n        In this example, we say its of format binary (do not try to introspect) and there are more than one files in it\n        \"\"\"\n        return LiteralType(blob=self._TYPE_INFO)\n\n    def to_literal(\n        self,\n        ctx: FlyteContext,\n        python_val: MyDataset,\n        python_type: Type[MyDataset],\n        expected: LiteralType,\n    ) -> Literal:\n        \"\"\"\n        This method is used to convert from given python type object ``MyDataset`` to the Literal representation\n        \"\"\"\n        # Step 1: lets upload all the data into a remote place recommended by Flyte\n        remote_dir = ctx.file_access.get_random_remote_directory()\n        ctx.file_access.upload_directory(python_val.base_dir, remote_dir)\n        # Step 2: lets return a pointer to this remote_dir in the form of a literal\n        return Literal(\n            scalar=Scalar(\n                blob=Blob(uri=remote_dir, metadata=BlobMetadata(type=self._TYPE_INFO))\n            )\n        )\n\n    def to_python_value(\n        self, ctx: FlyteContext, lv: Literal, expected_python_type: Type[MyDataset]\n    ) -> MyDataset:\n        \"\"\"\n        In this function we want to be able to re-hydrate the custom object from Flyte Literal value\n        \"\"\"\n        # Step 1: lets download remote data locally\n        local_dir = ctx.file_access.get_random_local_directory()\n        ctx.file_access.download_directory(lv.scalar.blob.uri, local_dir)\n        # Step 2: create the MyDataset object\n        return MyDataset(base_dir=local_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we can use MyDataset in our tasks, we need to let flytekit know that ``MyDataset`` should be considered as a\nvalid type. This is done using the :py:func:`flytekit.annotated.type_engine.TypeEngine.register` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "TypeEngine.register(MyDatasetTransformer())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the new type should be ready to use. Let us write an example generator and consumer for this new datatype\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@task\ndef generate() -> MyDataset:\n    d = MyDataset()\n    for i in range(3):\n        fp = d.new_file(f\"x{i}\")\n        with open(fp, \"w\") as f:\n            f.write(f\"Contents of file{i}\")\n\n    return d\n\n\n@task\ndef consume(d: MyDataset) -> str:\n    s = \"\"\n    for f in d.files:\n        with open(f) as fp:\n            s += fp.read()\n            s += \"\\n\"\n    return s\n\n\n@workflow\ndef wf() -> str:\n    return consume(d=generate())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can run this workflow locally and test it. Remember even when you run it locally, flytekit will excercise the\nentire path\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n    print(wf())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}