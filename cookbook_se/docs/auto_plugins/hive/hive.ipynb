{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Write a Hive Task\n\nTasks often start with a data gathering step, and often that data is gathered through Hive. Flytekit allows users to run\nany kind of Hive query (including queries with multiple statements and staging query commands).\n\nThe principal concept to understand with respect to Hive or any other query-engine based task is how Flyte interacts\nwith the system. That is, when I write a query, how does Flyte become aware of the result? From the user's perspective,\nthis is done by carefully constructing your query.\n\nWhen a Hive (or other querying) task runs, two things need to happen: a) The output data needs to be written to a place\naccessible to Flyte, and b) Flyte needs to know exactly what that location is.\n\nYou get a couple templating args to help make that happen, along with the usual input interpolation that Flyte provides.\n\n* ``.PerRetryUniqueKey`` - This is a string that will be ``[a-zA-Z0-9_]`` and start with a character. It will be unique\n  per retry. Feel free to use it to name temp tables.\n* ``RawOutputDataPrefix`` - This is the \"directory\" (S3/GCS output prefix) where Flyte will expect the outputs. You\n  should write the outputs to this location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from flytekit import workflow, kwtypes, task\nfrom flytekitplugins.hive import HiveTask, HiveSelectTask\nfrom flytekitplugins.hive.task import HiveConfig\nfrom flytekit.types.schema import FlyteSchema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the world's simplest query. Note that in order for registration to work properly, you'll need to give your\nHive task a name that's unique across your project/domain for your Flyte installation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hive_task_no_io = HiveTask(\n    name=\"recipes.sql.hive.no_io\",\n    inputs={},\n    task_config=HiveConfig(cluster_label=\"flyte\"),\n    query_template=\"\"\"\n        select 1\n    \"\"\",\n    output_schema_type=None,\n)\n\n\n@workflow\ndef no_io_wf():\n    return hive_task_no_io()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a hive task that demonstrates how you would construct your typical read query. Note where the ``select 1`` is.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hive_task_w_out = HiveTask(\n    name=\"recipes.sql.hive.w_out\",\n    inputs={},\n    task_config=HiveConfig(cluster_label=\"flyte\"),\n    query_template=\"\"\"\n    CREATE TEMPORARY TABLE {{ .PerRetryUniqueKey }}_tmp AS select 1;\n    CREATE EXTERNAL TABLE {{ .PerRetryUniqueKey }} LIKE {{ .PerRetryUniqueKey }}_tmp STORED AS PARQUET;\n    ALTER TABLE {{ .PerRetryUniqueKey }} SET LOCATION '{{ .RawOutputDataPrefix }}';\n    INSERT OVERWRITE TABLE {{ .PerRetryUniqueKey }}\n        SELECT *\n        FROM {{ .PerRetryUniqueKey }}_tmp;\n    DROP TABLE {{ .PerRetryUniqueKey }};\n    \"\"\",\n    output_schema_type=FlyteSchema,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There is a helper task that will automatically do the wrapping above. Please be patient as we fill out these docs.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@workflow\ndef with_output_wf() -> FlyteSchema:\n    return hive_task_w_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This just demonstrates the things you can do. Note that when an input is a FlyteSchema, the value filled in will\nbe the uri, i.e. where the data is stored.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "demo_all = HiveSelectTask(\n    name=\"recipes.sql.hive.demo_all\",\n    inputs=kwtypes(ds=str, earlier_schema=FlyteSchema),\n    task_config=HiveConfig(cluster_label=\"flyte\"),\n    select_query=\"\"\"\n    SELECT '.PerRetryUniqueKey' as template_key, '{{ .PerRetryUniqueKey }}' as template_value \n    UNION\n    SELECT '.RawOutputDataPrefix' as template_key, '{{ .RawOutputDataPrefix }}' as template_value\n    UNION\n    SELECT '.inputs.earlier_schema' as template_key, '{{ .inputs.earlier_schema }}' as template_value\n    UNION\n    SELECT '.inputs.ds' as template_key, '{{ .inputs.ds }}' as template_value\n    \"\"\",\n    output_schema_type=FlyteSchema,\n)\n\n\n@task\ndef print_schema(s: FlyteSchema):\n    df = s.open().all()\n    print(df.to_markdown())\n\n\n@workflow\ndef full_hive_demo_wf() -> FlyteSchema:\n    s = hive_task_w_out()\n    demo_schema = demo_all(ds=\"2020-01-01\", earlier_schema=s)\n    print_schema(s=demo_schema)\n    return demo_schema"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}