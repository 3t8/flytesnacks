{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Running Distributed Pytorch Training using KF PytorchOperator\nThis example is adapted from the default example available on Kubeflow's pytorch site.\n`here <https://github.com/kubeflow/pytorch-operator/blob/b7fef224fef1ef0117f6e74961b557270fcf4b04/examples/mnist/mnist.py>`_\nIt has been modified to show how to integrate it with Flyte and can be probably simplified and cleaned up.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport typing\nfrom dataclasses import dataclass\n\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nfrom dataclasses_json import dataclass_json\nfrom flytekit import task, Resources, workflow\nfrom flytekitplugins.kfpytorch import PyTorch\nfrom flytekit.types.directory import TensorboardLogs\nfrom flytekit.types.file import PythonPickledFile, PNGImageFile\nfrom tensorboardX import SummaryWriter\nfrom torch import distributed as dist, nn, optim\nfrom torchvision import datasets, transforms\n\nWORLD_SIZE = int(os.environ.get(\"WORLD_SIZE\", 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Actual model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4 * 4 * 50)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trainer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, writer, log_interval):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % log_interval == 0:\n            print(\n                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss={:.4f}\".format(\n                    epoch,\n                    batch_idx * len(data),\n                    len(train_loader.dataset),\n                    100.0 * batch_idx / len(train_loader),\n                    loss.item(),\n                )\n            )\n            niter = epoch * len(train_loader) + batch_idx\n            writer.add_scalar(\"loss\", loss.item(), niter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader, writer, epoch):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(\n                output, target, reduction=\"sum\"\n            ).item()  # sum up batch loss\n            pred = output.max(1, keepdim=True)[\n                1\n            ]  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    print(\"\\naccuracy={:.4f}\\n\".format(float(correct) / len(test_loader.dataset)))\n    accuracy = float(correct) / len(test_loader.dataset)\n    writer.add_scalar(\"accuracy\", accuracy, epoch)\n    return accuracy\n\n\ndef epoch_step(\n    model, device, train_loader, test_loader, optimizer, epoch, writer, log_interval\n):\n    train(model, device, train_loader, optimizer, epoch, writer, log_interval)\n    return test(model, device, test_loader, writer, epoch)\n\n\ndef should_distribute():\n    return dist.is_available() and WORLD_SIZE > 1\n\n\ndef is_distributed():\n    return dist.is_available() and dist.is_initialized()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Hyperparameters\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@dataclass_json\n@dataclass\nclass Hyperparameters(object):\n    \"\"\"\n    Args:\n        batch_size: input batch size for training (default: 64)\n        test_batch_size: input batch size for testing (default: 1000)\n        epochs: number of epochs to train (default: 10)\n        learning_rate: learning rate (default: 0.01)\n        sgd_momentum: SGD momentum (default: 0.5)\n        seed: random seed (default: 1)\n        log_interval: how many batches to wait before logging training status\n        dir: directory where summary logs are stored\n    \"\"\"\n\n    backend: str = dist.Backend.GLOO\n    sgd_momentum: float = 0.5\n    seed: int = 1\n    log_interval: int = 10\n    batch_size: int = 64\n    test_batch_size: int = 1000\n    epochs: int = 10\n    learning_rate: float = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Actual Training algorithm\nThe output model using `torch.save` saves the `state_dict` as described\n`in pytorch docs <https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-and-loading-models>`_.\nA common convention is to have the ``.pt`` extension for the file\n\nNotice we are also generating an output variable called logs, these logs can be used to visualize the training in\nTensorboard and are the output of the `SummaryWriter` interface\nRefer to section `pytorch_tensorboard` to visualize the outputs of this example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "TrainingOutputs = typing.NamedTuple(\n    \"TrainingOutputs\",\n    epoch_accuracies=typing.List[float],\n    model_state=PythonPickledFile,\n    logs=TensorboardLogs,\n)\n\n\n@task(\n    task_config=PyTorch(\n        num_workers=2,\n        per_replica_requests=Resources(cpu=\"500m\", mem=\"4Gi\", gpu=\"1\"),\n        per_replica_limits=Resources(mem=\"8Gi\", gpu=\"1\"),\n    ),\n    retries=2,\n    cache=True,\n    cache_version=\"1.0\",\n    container_image=\"{{.image.default.fqn}}:pytorch-{{.image.default.version}}\",\n)\ndef mnist_pytorch_job(hp: Hyperparameters) -> TrainingOutputs:\n    log_dir = \"logs\"\n    writer = SummaryWriter(log_dir)\n\n    torch.manual_seed(hp.seed)\n\n    use_cuda = torch.cuda.is_available()\n    print(f\"Use cuda {use_cuda}\")\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    print(\"Using device: {}, world size: {}\".format(device, WORLD_SIZE))\n\n    if should_distribute():\n        print(\"Using distributed PyTorch with {} backend\".format(hp.backend))\n        dist.init_process_group(backend=hp.backend)\n\n    # LOAD Data\n    kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n    train_loader = torch.utils.data.DataLoader(\n        datasets.MNIST(\n            \"../data\",\n            train=True,\n            download=True,\n            transform=transforms.Compose(\n                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n            ),\n        ),\n        batch_size=hp.batch_size,\n        shuffle=True,\n        **kwargs,\n    )\n    test_loader = torch.utils.data.DataLoader(\n        datasets.MNIST(\n            \"../data\",\n            train=False,\n            transform=transforms.Compose(\n                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n            ),\n        ),\n        batch_size=hp.test_batch_size,\n        shuffle=False,\n        **kwargs,\n    )\n\n    # Train the model\n    model = Net().to(device)\n\n    if is_distributed():\n        Distributor = (\n            nn.parallel.DistributedDataParallel\n            if use_cuda\n            else nn.parallel.DistributedDataParallelCPU\n        )\n        model = Distributor(model)\n\n    optimizer = optim.SGD(\n        model.parameters(), lr=hp.learning_rate, momentum=hp.sgd_momentum\n    )\n\n    accuracies = [\n        epoch_step(\n            model,\n            device,\n            train_loader,\n            test_loader,\n            optimizer,\n            epoch,\n            writer,\n            hp.log_interval,\n        )\n        for epoch in range(1, hp.epochs + 1)\n    ]\n\n    # Save the model\n    model_file = \"mnist_cnn.pt\"\n    torch.save(model.state_dict(), model_file)\n\n    return TrainingOutputs(\n        epoch_accuracies=accuracies,\n        model_state=PythonPickledFile(model_file),\n        logs=TensorboardLogs(log_dir),\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Let us plot the accuracy\nWe will output the accuracy plot as a PNG image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@task\ndef plot_accuracy(epoch_accuracies: typing.List[float]) -> PNGImageFile:\n    # summarize history for accuracy\n    plt.plot(epoch_accuracies)\n    plt.title(\"Accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    accuracy_plot = \"accuracy.png\"\n    plt.savefig(accuracy_plot)\n\n    return PNGImageFile(accuracy_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a pipeline\nnow the training and the plotting can be together put into a pipeline, in which case the training is performed first\nfollowed by the plotting of the accuracy. Data is passed between them and the workflow itself outputs the image and\nthe serialize model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@workflow\ndef pytorch_training_wf(\n    hp: Hyperparameters,\n) -> (PythonPickledFile, PNGImageFile, TensorboardLogs):\n    accuracies, model, logs = mnist_pytorch_job(hp=hp)\n    plot = plot_accuracy(epoch_accuracies=accuracies)\n    return model, plot, logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run the model locally\nIt is possible to run the model locally with almost no modifications (as long as the code takes care of the resolving\nif distributed or not)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n    model, plot, logs = pytorch_training_wf(\n        hp=Hyperparameters(epochs=2, batch_size=128)\n    )\n    print(f\"Model: {model}, plot PNG: {plot}, Tensorboard Log Dir: {logs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Rendering the output logs in tensorboard\nWhen running locally, the output of execution looks like\n\n.. code-block::\n\n  Model: /tmp/flyte/20210110_214129/mock_remote/8421ae4d041f76488e245edf3f4360d5/my_model.h5, plot PNG: /tmp/flyte/20210110_214129/mock_remote/cf6a2cd9d3ded89ed814278a8fb3678c/accuracy.png, Tensorboard Log Dir: /tmp/flyte/20210110_214129/mock_remote/a4b04e58e21f26f08f81df24094d6446/\n\nYou can use the ``Tensorboard Log Dir: /tmp/flyte/20210110_214129/mock_remote/a4b04e58e21f26f08f81df24094d6446/`` as\nan input to tensorboard to visualize the training as follows\n\n.. prompt:: bash\n\n  tensorboard --logdir /tmp/flyte/20210110_214129/mock_remote/a4b04e58e21f26f08f81df24094d6446/\n\n\nIf running remotely (executing on Flyte hosted environment), the workflow execution outputs can be retrieved.\nRefer to .. TODO.\nYou can retrieve the outputs - which will be a path to a blob store like S3, GCS, minio, etc. Tensorboad can be\npointed to on your local laptop to visualize the results.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}